{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f00e4803-ee1f-45b9-becf-f5709beca5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "093d8f75-b081-4d75-986d-bce3a8c5b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# @dsl.component(\n",
    "#     base_image='tensorflow/tensorflow:latest',\n",
    "#     packages_to_install=['pandas','s3fs','boto3','typing','docstring_parser']\n",
    "# )\n",
    "\n",
    "# def predict_image_from_minio(image_name: str, s3_bucket: str, s3_endpoint: str, access_key: str, secret_key: str) -> int:\n",
    "#     \"\"\"\n",
    "#     This function loads an image from MinIO, preprocesses it, and uses the MNIST model to predict the digit.\n",
    "\n",
    "#     Args:\n",
    "#     - image_name (str): The name of the image stored in MinIO.\n",
    "#     - s3_bucket (str): The MinIO bucket where the image and model are stored.\n",
    "#     - s3_endpoint (str): The MinIO endpoint URL.\n",
    "#     - access_key (str): The MinIO access key.\n",
    "#     - secret_key (str): The MinIO secret key.\n",
    "\n",
    "#     Returns:\n",
    "#     - int: The predicted digit.\n",
    "#     \"\"\"\n",
    "\n",
    "#     import numpy as np\n",
    "#     import boto3\n",
    "#     from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "#     from tensorflow.keras.models import load_model\n",
    "#     from typing import Tuple\n",
    "#     from kfp import dsl\n",
    "#     from typing import Tuple,NamedTuple\n",
    "#     from kfp import compiler\n",
    "#     from kfp.dsl import component\n",
    "\n",
    "#     # Step 1: Set up the MinIO client using boto3\n",
    "#     s3 = boto3.client('s3', \n",
    "#                       endpoint_url=s3_endpoint, \n",
    "#                       aws_access_key_id=access_key, \n",
    "#                       aws_secret_access_key=secret_key)\n",
    "\n",
    "#     # Step 2: Load the MNIST model from MinIO\n",
    "#     model_key = 'dn-data/sushant_model/model.h5'  # Assuming the model is stored as 'model.h5' in 'mnist-model' directory\n",
    "#     response_model = s3.get_object(Bucket=s3_bucket, Key=model_key)\n",
    "#     mnist_model = load_model(response_model['Body'])\n",
    "\n",
    "#     # Step 3: Preprocess the image for MNIST model\n",
    "#     def preprocess_image(image_path: str) -> np.ndarray:\n",
    "#         \"\"\"\n",
    "#         Preprocesses the image to match the input format required by the MNIST model.\n",
    "#         - Converts to grayscale.\n",
    "#         - Resizes to 28x28 pixels.\n",
    "#         - Normalizes the pixel values.\n",
    "#         - Expands dimensions to match the model's input shape.\n",
    "\n",
    "#         Args:\n",
    "#         - image_path (str): The path to the image file.\n",
    "\n",
    "#         Returns:\n",
    "#         - np.ndarray: The preprocessed image ready for prediction.\n",
    "#         \"\"\"\n",
    "#         img = load_img(image_path, color_mode=\"grayscale\", target_size=(28, 28))\n",
    "#         img_array = img_to_array(img)\n",
    "#         img_array = img_array / 255.0  # Normalize the image\n",
    "#         img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "#         return img_array\n",
    "\n",
    "#     # Step 4: Download the image from MinIO\n",
    "#     image_object = s3.get_object(Bucket=s3_bucket, Key=image_name)\n",
    "#     image_path = '/tmp/' + image_name  # Save to temporary file\n",
    "#     with open(image_path, 'wb') as f:\n",
    "#         f.write(image_object['Body'].read())\n",
    "\n",
    "#     # Step 5: Preprocess the downloaded image\n",
    "#     preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "#     # Step 6: Make a prediction using the MNIST model\n",
    "#     predictions = mnist_model.predict(preprocessed_image)\n",
    "#     predicted_digit = np.argmax(predictions)  # Get the predicted digit as the class with the highest probability\n",
    "\n",
    "#     return predicted_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7a75d1-9251-47ca-810f-c26f2bf4093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import ksp\n",
    "# import boto3\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from typing import Tuple\n",
    "# from kfp import dsl\n",
    "# from typing import Tuple,NamedTuple\n",
    "# from kfp import compiler\n",
    "# from kfp.dsl import component\n",
    "\n",
    "# @dsl.component(\n",
    "#     base_image='python:3.11',\n",
    "#     packages_to_install=['pandas','pyarrow','numpy','s3fs','boto3','psycopg2-binary']\n",
    "# )\n",
    "\n",
    "# def predict_image_from_minio(image_name: str) -> int:\n",
    "\n",
    "#     import pandas as pd\n",
    "#     import pickle\n",
    "#     import boto3\n",
    "#     \"\"\"\n",
    "#     This function loads an image from MinIO, preprocesses it, and uses the MNIST model to predict the digit.\n",
    "\n",
    "#     Args:\n",
    "#     - image_name (str): The name of the image stored in MinIO.\n",
    "#     - s3_bucket (str): The MinIO bucket where the image and model are stored.\n",
    "#     - s3_endpoint (str): The MinIO endpoint URL.\n",
    "#     - access_key (str): The MinIO access key.\n",
    "#     - secret_key (str): The MinIO secret key.\n",
    "\n",
    "#     Returns:\n",
    "#     - int: The predicted digit.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Step 1: Set up the MinIO client using boto3\n",
    "#     s3 = boto3.client('s3', \n",
    "#                       endpoint_url=\"http://dlytica-kube-vm.eastus.cloudapp.azure.com:32000\", \n",
    "#                       aws_access_key_id=\"adminuser\", \n",
    "#                       aws_secret_access_key=\"admin123\")\n",
    "\n",
    "#     # AWS_ACCESS_KEY_ID = \"adminuser\"\n",
    "#     # AWS_SECRET_ACCESS_KEY = \"admin123\"\n",
    "#     # S3_ENDPOINT = \"http://dlytica-kube-vm.eastus.cloudapp.azure.com:32000\"\n",
    "#     s3_bucket = \"dn-data\"\n",
    "\n",
    "    \n",
    "#     # s3 = boto3.client('s3', endpoint_url=S3_ENDPOINT, aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "#     # response = s3.get_object(Bucket=S3_BUCKET, Key='regression-model/model.pkl')\n",
    "#     # loaded_model = pickle.loads(response['Body'].read())\n",
    "\n",
    "\n",
    "#     # Step 2: Load the MNIST model from MinIO\n",
    "#     model_key = 'dn-data/sushant_model/model.h5'  # Assuming the model is stored as 'model.h5' in 'mnist-model' directory\n",
    "#     response_model = s3.get_object(Bucket=s3_bucket, Key=model_key)\n",
    "#     mnist_model = load_model(response_model['Body'])\n",
    "\n",
    "#     # Step 3: Preprocess the image for MNIST model\n",
    "#     def preprocess_image(image_path: str) -> np.ndarray:\n",
    "#         \"\"\"\n",
    "#         Preprocesses the image to match the input format required by the MNIST model.\n",
    "#         - Converts to grayscale.\n",
    "#         - Resizes to 28x28 pixels.\n",
    "#         - Normalizes the pixel values.\n",
    "#         - Expands dimensions to match the model's input shape.\n",
    "\n",
    "#         Args:\n",
    "#         - image_path (str): The path to the image file.\n",
    "\n",
    "#         Returns:\n",
    "#         - np.ndarray: The preprocessed image ready for prediction.\n",
    "#         \"\"\"\n",
    "#         img = load_img(image_path, color_mode=\"grayscale\", target_size=(28, 28))\n",
    "#         img_array = img_to_array(img)\n",
    "#         img_array = img_array / 255.0  # Normalize the image\n",
    "#         img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "#         return img_array\n",
    "\n",
    "#     # Step 4: Download the image from MinIO\n",
    "#     image_object = s3.get_object(Bucket=s3_bucket, Key=image_name)\n",
    "#     image_path = '/tmp/' + image_name  # Save to temporary file\n",
    "#     with open(image_path, 'wb') as f:\n",
    "#         f.write(image_object['Body'].read())\n",
    "\n",
    "#     # Step 5: Preprocess the downloaded image\n",
    "#     preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "#     # Step 6: Make a prediction using the MNIST model\n",
    "#     predictions = mnist_model.predict(preprocessed_image)\n",
    "#     predicted_digit = np.argmax(predictions)  # Get the predicted digit as the class with the highest probability\n",
    "\n",
    "#     return predicted_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f270994-9ac4-4584-9d80-c42542cbbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(predict_image_from_minio, package_path='pipeline_inference-v3.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edffcaca-d2b3-44f5-b977-75c903a1b5b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Components must be instantiated using keyword arguments. Positional parameters are not allowed (found 1 such parameters for component \"predict-image-from-minio\").",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the sample data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(sample_data)\n\u001b[0;32m---> 21\u001b[0m predicted_digit \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_image_from_minio\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted digit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_digit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kfp/dsl/base_component.py:76\u001b[0m, in \u001b[0;36mBaseComponent.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m task_inputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponents must be instantiated using keyword arguments. Positional \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters are not allowed (found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m such parameters for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomponent \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component_inputs:\n",
      "\u001b[0;31mTypeError\u001b[0m: Components must be instantiated using keyword arguments. Positional parameters are not allowed (found 1 such parameters for component \"predict-image-from-minio\")."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "import pandas as pd\n",
    "\n",
    "access_key = 'adminuser'\n",
    "img_name = '5.png'\n",
    "bucket_name ='dn-data'\n",
    "endpoint = 'http://dlytica-kube-vm.eastus.cloudapp.azure.com:32000' # MinIO endpoint\n",
    "secret_key = 'admin123' # MinIO secret key\n",
    "\n",
    "# sample_data = {\n",
    "#     'image_name' :  [img_name],# Replace with the actual image name in MinIO\n",
    "#     's3_bucket' : [bucket_name],  # MinIO bucket name\n",
    "#     's3_endpoint' : [endpoint],\n",
    "#     'access_key' : [access_key],\n",
    "#     'secret_key' : [secret_key]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame from the sample data\n",
    "# sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "# predicted_digit = predict_image_from_minio(sample_df)\n",
    "# print(f\"Predicted digit: {predicted_digit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fad6124-47a9-4c41-b3e2-4aecfd12e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline definition saved to mnist_prediction_pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp import dsl, compiler\n",
    "\n",
    "# Define the prediction component\n",
    "@dsl.component(\n",
    "    base_image='tensorflow/tensorflow:latest',\n",
    "    packages_to_install=['pandas', 's3fs', 'boto3', 'numpy', 'tensorflow', 'Pillow']\n",
    ")\n",
    "def predict_image_from_minio(\n",
    "    image_name: str, \n",
    "    s3_bucket: str, \n",
    "    s3_endpoint: str, \n",
    "    access_key: str, \n",
    "    secret_key: str\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    This function loads an image from MinIO, preprocesses it, and uses the MNIST model to predict the digit.\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import boto3\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "    import os\n",
    "\n",
    "    # Step 1: Set up the MinIO client using boto3\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=s3_endpoint,\n",
    "        aws_access_key_id=access_key,\n",
    "        aws_secret_access_key=secret_key\n",
    "    )\n",
    "\n",
    "    # Step 2: Load the MNIST model from MinIO\n",
    "    model_key = 'sushant_model/detect-digits.h5'\n",
    "    response_model = s3.get_object(Bucket=s3_bucket, Key=model_key)\n",
    "\n",
    "    # Save the model content to a temporary file\n",
    "    model_temp_path = \"/tmp/mnist_model.h5\"\n",
    "    with open(model_temp_path, 'wb') as model_file:\n",
    "        model_file.write(response_model['Body'].read())\n",
    "    mnist_model = load_model(model_temp_path)\n",
    "\n",
    "    # Step 3: Preprocess the image for MNIST model\n",
    "    def preprocess_image(image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocesses the image to match the input format required by the MNIST model.\n",
    "        \"\"\"\n",
    "        img = load_img(image_path, color_mode=\"grayscale\", target_size=(28, 28))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the image\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        return img_array\n",
    "\n",
    "    # Step 4: Download the image from MinIO\n",
    "    image_object = s3.get_object(Bucket=s3_bucket, Key=image_name)\n",
    "    image_temp_path = '/tmp/' + os.path.basename(image_name)  # Save to a temporary file\n",
    "    with open(image_temp_path, 'wb') as image_file:\n",
    "        image_file.write(image_object['Body'].read())\n",
    "\n",
    "    # Step 5: Preprocess the downloaded image\n",
    "    preprocessed_image = preprocess_image(image_temp_path)\n",
    "\n",
    "    # Step 6: Make a prediction using the MNIST model\n",
    "    predictions = mnist_model.predict(preprocessed_image)\n",
    "    predicted_digit = np.argmax(predictions)  # Get the predicted digit as the class with the highest probability\n",
    "\n",
    "\n",
    "    print(f\"The predicted digit is : {int(predicted_digit)}\")\n",
    "    # Ensure that the predicted digit is returned as a native Python int\n",
    "    return int(predicted_digit)\n",
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(name=\"mnist-prediction-pipeline\", description=\"A pipeline to predict digits using MNIST model from MinIO\")\n",
    "def mnist_pipeline(\n",
    "    image_name: str,\n",
    "    s3_bucket: str,\n",
    "    s3_endpoint: str,\n",
    "    access_key: str,\n",
    "    secret_key: str\n",
    "):\n",
    "    # Add the predict component to the pipeline\n",
    "    prediction = predict_image_from_minio(\n",
    "        image_name=image_name,\n",
    "        s3_bucket=s3_bucket,\n",
    "        s3_endpoint=s3_endpoint,\n",
    "        access_key=access_key,\n",
    "        secret_key=secret_key\n",
    "    )\n",
    "\n",
    "    # Print the prediction\n",
    "    prediction.set_display_name(\"Digit Prediction\")\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_file_path = \"mnist_prediction_pipeline.yaml\"\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=mnist_pipeline,\n",
    "    package_path=pipeline_file_path\n",
    ")\n",
    "\n",
    "print(f\"Pipeline definition saved to {pipeline_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43985430-3ec8-4e6c-ad15-6f628d1a0032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
